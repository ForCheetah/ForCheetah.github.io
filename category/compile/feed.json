{
    "version": "https://jsonfeed.org/version/1",
    "title": "Пусть этот камень будет более крепким, чем человек • All posts by \"compile\" category",
    "description": "有自己的博客很帅，但是我很懒，要命！！！",
    "home_page_url": "https://forcheetah.github.io",
    "items": [
        {
            "id": "https://forcheetah.github.io/2025/01/14/aicompile02/",
            "url": "https://forcheetah.github.io/2025/01/14/aicompile02/",
            "title": "【AI编译】如何进行layer-group",
            "date_published": "2025-01-14T12:09:18.353Z",
            "content_html": "<h1 id=\"前言\"><a class=\"anchor\" href=\"#前言\">#</a> 前言</h1>\n<p>本篇介绍 AI 编译领域 layer-group 算法。</p>\n<p>本篇文章参考过 <a href=\"https://baijiahao.baidu.com/s?id=1787593090401250411&amp;wfr=spider&amp;for=pc\">《超强干货！地平线编译器大牛的编译优化实践总结》</a>，<a href=\"https://github.com/Arm-China/Compass_Optimizer\">《Arm 周易编译器工程》</a>，<a href=\"https://tpumlir.org/docs/developer_manual/10_layergroup.html#group\">《算能 TPU layer group 讲解》</a>，<a href=\"https://www.bilibili.com/video/BV1wo4y1z7AG/\">《算能 TPU 视频讲解》</a> 等文章和工程，欢迎大家参考。</p>\n<p>作为初学者，错误在所难免，还望不吝赐教。</p>\n<h1 id=\"layer-group\"><a class=\"anchor\" href=\"#layer-group\">#</a> Layer group</h1>\n<p>如图所示，AI 编译优化的基本流程是 1. 图优化 (算子融合，常量折叠等) 2. 拆分 (layer group 和 tiling) 3. 并行和调度。最后得到当前编译的时间消耗。</p>\n<p><img loading=\"lazy\" data-src=\"1736856461365.jpg\" alt=\"如图1所示\"></p>\n<p>在 AI 编译领域，LayerGroup 指的是将神经网络中的多个层（layers (Operator) ）组合成一个逻辑单元或模块的过程。</p>\n<p>一般而言设备的运行内存很大，比如电脑的运行内存 16GB，但是它的速度比较慢，我们把它叫做 Global Memory。而做神经网络推理的专用 NPU 芯片，它的高速缓存速度很快，但是空间可能只有几 MB，我们把它叫做 Cache。我们无法将网络模型所有 layer 全部加载到 cache 中，那么意味着每个算子都需要 Cache 和外部 Global Memory 的交互，load 输入数据、store 结果。</p>\n<p>所以需要将网络拆分成小的 layer group。一般默认只有进入和退出 layer group 的时候，才需要和外部的 Global Memory 做 Load/Store 操作去交互。把需要的数据 load 进来，将结果数据 store 出去。layer group 减少了 Load/Store 操作，同时 layer group 也是后续 tiling、调度等操作的基本单元，降低了问题复杂度。</p>\n<h1 id=\"动态规划搜索\"><a class=\"anchor\" href=\"#动态规划搜索\">#</a> 动态规划搜索</h1>\n<p><img loading=\"lazy\" data-src=\"1736856461365.jpg\" alt=\"如图1所示\"></p>\n<p>还是这张图，如何划分 layer group 呢？图里面只有四个算子，可以 1,2 划分一组，3,4 划分一组；也可以 1 划为一组，2,3,4 划分另一组；甚至 1,2,3,4 全部划分为一组。不同的划分方式，最后得到的 Cost 也不同。<br>\n为了找到最优的划分方式，不得不搜索所有划分方案。</p>\n<p>假设网络有 n 层，则 n 层中间有 n-1 个间隔。选取 0 个间隔，也就是 n 层全部划分为一组，是 C (n-1, 0)；选取 1 个间隔，也就是分成两组，是 C (n-1,1)；选取 2 个间隔，也就是划分三组，是 C (n-1,2)；以此类推， C (n-1, 0)+C (n-1,1)+C (n-1,2)+……+C (n-1,n-1)，根据二项式定理，需要 2^(n-1) 次搜索。</p>\n<p>指数式增长计算量太大，是不可接受的。</p>\n<p>可以采用动态规划的思想来减少搜索次数。</p>\n<p>我们以 100 层网络为例。设 <code>f(n)</code>  为从第 0 层到达第 n 层最短用时。令  <code>f(-1) = 0</code>  ， <code>cost(x,y)</code>  为从 x 层到 y 层作为一个 group 的开销。则：</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">11</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">99</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token function\">min</span><span class=\"token punctuation\">(</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">99</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">99</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">;</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span> <span class=\"token punctuation\">;</span> <span class=\"token function\">f</span><span class=\"token punctuation\">(</span><span class=\"token number\">98</span><span class=\"token punctuation\">)</span><span class=\"token operator\">+</span><span class=\"token function\">cost</span><span class=\"token punctuation\">(</span><span class=\"token number\">99</span><span class=\"token punctuation\">,</span><span class=\"token number\">99</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">)</span></pre></td></tr></table></figure><p>这就需要提前计算一个 cost table。</p>\n<p><img loading=\"lazy\" data-src=\"1736856527679.jpg\" alt=\"如图2所示\"></p>\n<p>cost table 如图所示。我们要做的就是以从 x 层到 y 层作为一个 group，计算开销 <code>cost(x,y)</code>  并保存下来。对于一个 n 层的网络来说，需要搜索的 layer group 数量为： 1+2+…+n = n (n+1)/2 。搜索次数从原来的 2^(n-1) 指数函数，已经降到幂函数。</p>\n<p>但是当网络层数过多时，搜索量还是很大，可以限制最大搜索长度，例如最长支持 50 层，那么 cost table 就变成下面这个样子：</p>\n<p><img loading=\"lazy\" data-src=\"1736856542354.jpg\" alt=\"如图3所示\"></p>\n<p>现在对于 n 层网络，搜索数量降到 50*n 。</p>\n<p>还可以启发式的剪枝优化，优化掉明显不会有收益的分支，进一步降低搜索的时间消耗。</p>\n<h1 id=\"后记\"><a class=\"anchor\" href=\"#后记\">#</a> 后记</h1>\n<p>本博客目前以及可预期的将来都不会支持评论功能。各位大侠如若有指教和问题，可以在我的 <a href=\"https://github.com/ForCheetah/ForCheetah.github.io\">github 项目</a> 或随便一个项目下提出 issue，或者<a href=\"https://www.zhihu.com/people/guai-dao-ji-de-3-50\">知乎</a> 私信，并指明哪一篇博客，我看到一定及时回复，感激不尽！global_info)</p>\n<p><code>runtime_mod</code></p>\n",
            "tags": [
                "compile",
                "AI"
            ]
        },
        {
            "id": "https://forcheetah.github.io/2024/10/18/aicompile01/",
            "url": "https://forcheetah.github.io/2024/10/18/aicompile01/",
            "title": "【AI编译】Tiling操作能优化什么时间",
            "date_published": "2024-10-18T13:44:56.351Z",
            "content_html": "<h1 id=\"前言\"><a class=\"anchor\" href=\"#前言\">#</a> 前言</h1>\n<p>本篇讲解 Tiling 操作为什么能够优化神经网络推理。</p>\n<p>也可以参考 <a href=\"https://www.hiascend.com/developer/techArticles/20240920-1?envFlag=1\">《Ascend C 算子优化实用技巧 04——Tiling 优化》</a></p>\n<p>作为初学者，错误在所难免，还望不吝赐教。</p>\n<h1 id=\"什么是tiling\"><a class=\"anchor\" href=\"#什么是tiling\">#</a> 什么是 tiling</h1>\n<p>无法完整的容纳算子的输入与输出，需要每次搬运一部分输入进行计算然后搬出，再搬运下一部分输入进行计算，直到得到完整的最终结果，这个数据切分、分块计算的过程称之为 Tiling，切分数据的算法称为 Tiling 算法或者 Tiling 策略。</p>\n<h1 id=\"tile算子和tiling的区别\"><a class=\"anchor\" href=\"#tile算子和tiling的区别\">#</a> tile 算子和 tiling 的区别</h1>\n<p>我们先问一问语言大模型两者的区别：</p>\n<h2 id=\"神经网络推理中的tile算子\"><a class=\"anchor\" href=\"#神经网络推理中的tile算子\">#</a> 神经网络推理中的 Tile 算子</h2>\n<p>在神经网络中，会发现 tile 作为一个节点算子出现。Tile 算子（或称为 Tiling 操作）是一种张量操作，它的功能是将输入张量沿着指定的维度重复一定次数。该算子需要指定两个参数：</p>\n<ul>\n<li>1.reps<br>\n（重复次数）：这是一个整数列表，定义了每个维度上的重复次数。列表的长度必须与输入张量的维度相匹配，或者至少与你想要扩展的那些维度相匹配。如果对于某个维度你不希望进行复制，可以设置为 1。</li>\n<li>2.axis<br>\n（轴 / 维度）：虽然某些框架可能不需要显式指定轴，因为它们可以通过 reps 的结构来推断，但有些情况下需要明确指出哪些维度应该被复制。</li>\n</ul>\n<p>例如，假设有一个形状为 (2, 3) 的二维张量，并且你想沿第一个维度（行方向）重复两次，沿第二个维度（列方向）重复三次，那么你可以使用 Tile 算子并设置 reps=[2, 3]。这样操作后，输出张量将会是一个形状为 (4, 9) 的新张量，其中原始张量的内容被按照指定的方式进行了复制。</p>\n<p>在不同的深度学习库中，Tile 算子的实现可能会有所不同。例如，在 TensorFlow 中，它是 tf.tile () 函数；而在 PyTorch 中，则对应的是 torch.tile () 或者 .repeat () 方法。每种实现都有其特定的语法和用法，但核心概念是一致的。</p>\n<h2 id=\"ai编译优化中的tiling操作\"><a class=\"anchor\" href=\"#ai编译优化中的tiling操作\">#</a> AI 编译优化中的 tiling 操作</h2>\n<p>在 AI 编译领域，特别是针对深度学习模型的优化过程中，“tiling”（平铺）操作是指一种将计算任务分解成更小、更易于管理的子任务的技术。这种技术通常用于提高计算效率和内存使用效率，尤其是在处理大规模数据集或高维度张量时。</p>\n<p>Tiling 的主要目的是：</p>\n<ul>\n<li>1. 减少内存访问开销：通过将大块数据划分为较小的 “瓦片”，可以将这些小块数据加载到高速缓存中，从而减少对外部存储器的访问次数。这有助于利用 CPU 或 GPU 的高速缓存来加速计算过程。</li>\n<li>2. 并行化处理：每个 “瓦片” 可以独立处理，这意味着它们可以在多核处理器上并行执行，或者在 GPU 等并行计算架构上高效地分发给不同的线程或流处理器。</li>\n<li>3. 更好地利用硬件资源：通过适当调整瓦片大小，可以确保计算单元能够被充分利用，同时避免因单个任务过大导致的资源浪费。</li>\n<li>4. 改善局部性：合理设置的瓦片尺寸可以帮助保持良好的空间局部性和时间局部性，使得数据在被处理前已经被预取到了更快的存储层次中。</li>\n<li>5. 降低峰值内存需求：对于某些运算来说，一次性加载整个输入可能需要大量的内存。通过 tilling，我们可以仅处理当前所需的那部分数据，从而降低了对系统内存的需求。<br>\n例如，在卷积神经网络 (CNN) 中，一个常见的做法是将图像分割成多个小块，并且只在这些小块上进行卷积运算，而不是在整个图像上进行。这样做不仅可以减少每次计算所需的数据量，还能促进更好的并行化。</li>\n</ul>\n<p>Tiling 策略的选择取决于具体的硬件特性以及所处理数据的特点。在实际应用中，通常需要根据目标平台和具体应用场景来精心设计合适的 tilling 方案。一些自动化的工具和框架如 TensorFlow XLA、TVM (Tensor Virtual Machine) 等提供了高级别的 API 来帮助开发者实现高效的 tilling 优化。</p>\n<h2 id=\"两个tile是完全不同的概念\"><a class=\"anchor\" href=\"#两个tile是完全不同的概念\">#</a> 两个 tile 是完全不同的概念</h2>\n<p>两个 “tile” 概念虽然名字相似，但它们在不同的上下文中使用，并且具有不同的含义和用途：</p>\n<p>1. 神经网络中的 Tile 算子：</p>\n<ul>\n<li>在这个上下文中，Tile 是指一种张量操作，它将输入张量沿着指定维度重复一定次数。</li>\n<li>它主要用于数据处理阶段，例如当你需要复制或扩展张量以匹配某些特定的尺寸要求时。</li>\n<li>例子包括 TensorFlow 中的 tf.tile () 函数或 PyTorch 中的.repeat () 方法。</li>\n</ul>\n<p>2.AI 编译领域的 Tiling（平铺）：</p>\n<ul>\n<li>这里的 Tiling 是一种优化技术，用于将计算任务分解成更小的、可管理的部分，以便于更好地利用硬件资源，如缓存和并行计算能力。</li>\n<li>它通常是在模型优化阶段使用的，目的是提高计算效率、减少内存访问开销、促进并行化处理等。</li>\n<li>Tiling 可以应用于各种类型的运算，比如卷积运算中将图像分割成小块来处理。</li>\n</ul>\n<p>总结来说，尽管两者都涉及到了 “复制” 或 “分块” 的概念，但是神经网络中的 Tile 算子更多地关注于数据结构的操作，而 AI 编译领域的 Tiling 则是一个优化策略，旨在提升程序执行的性能。这两个概念分别属于数据处理和性能优化的不同领域。</p>\n<h1 id=\"案例\"><a class=\"anchor\" href=\"#案例\">#</a> 案例</h1>\n<p>一台电脑的内存很大，现在主流配置 16GB，甚至 32GB，虽然空间很大，但是它的速度比较慢，我们把它叫做 Global Memory。</p>\n<p>专用的 NPU 芯片用来做神经网络推理，它的高速缓存速度很快，但是空间可能只有几 MB，我们把它叫做 Cache。</p>\n<p>为了获取更快的运算速度，tensor 需要加载到 Cache 中进行计算，但是当算子需要占用的空间超过 Cache 的空间时，需要不断的进行数据搬运，导致算子搬入或搬出数据变为算子整个运行过程的性能瓶颈。</p>\n<p><img loading=\"lazy\" data-src=\"1729258859529.jpg\" alt=\"AI\"></p>\n<p>如上图所示：</p>\n<p>假设现在有 300 个数，需要连续经过三个 add 算子进行加操作，分别是 <code>add_1</code> ， <code>add_2</code>  和 <code>add_3</code> ，最终仍然输出 300 个数。</p>\n<p>但是 Cache 只能够存放 100 个数。</p>\n<p>在没有 tiling 操作的情况下：计算 <code>add_1</code>  时，需要将 (0,100) 个数 load 到 Cache，计算完毕后，需要将这 (0,100) store 回 global memory，为下一百个数腾出空间【接下来的计算 Cache 未命中】；然后加载 load (100,200) 的数据，继续计算 <code>add_1</code> 。以此类推，在没有 tiling 操作的情况下，计算完 <code>add_1</code> ， <code>add_2</code>  和 <code>add_3</code>  需要 load 和 store 操作的数据都是 900。</p>\n<p>在 tiling 的情况下，会提前将数据分块，分成 (0,100)，(100,200) 和 (200,300)。加载 (0,100)，接连计算 <code>add_1</code> ， <code>add_2</code>  和 <code>add_3</code> 。计算 <code>add_2</code>  时发现 Cache 中的数据正是所需要的数据【Cache 命中】。计算流程如图所示，整个计算下来，load 和 store 操作的数据都是 300。</p>\n<p><img loading=\"lazy\" data-src=\"a.jpg\" alt=\"图片\"></p>\n<p>tiling 操作提高了 cache 的命中率，避免了频繁搬运带来的时间损耗。<br>\n从图上看，同一 group 中包含的超出 cache 算子越多，tiling 带来的收益越大。</p>\n<h1 id=\"后记\"><a class=\"anchor\" href=\"#后记\">#</a> 后记</h1>\n<p>本博客目前以及可预期的将来都不会支持评论功能。各位大侠如若有指教和问题，可以在我的 <a href=\"https://github.com/ForCheetah/ForCheetah.github.io\">github 项目</a> 或随便一个项目下提出 issue，或者<a href=\"https://www.zhihu.com/people/guai-dao-ji-de-3-50\">知乎</a> 私信，并指明哪一篇博客，我看到一定及时回复，感激不尽！</p>\n",
            "tags": [
                "compile",
                "AI"
            ]
        }
    ]
}