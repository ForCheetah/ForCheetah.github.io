{
    "version": "https://jsonfeed.org/version/1",
    "title": "Пусть этот камень будет более крепким, чем человек • All posts by \"tengine\" category",
    "description": "有自己的博客很帅，但是我很懒，要命！！！",
    "home_page_url": "https://forcheetah.github.io",
    "items": [
        {
            "id": "https://forcheetah.github.io/2025/04/27/Tengine02/",
            "url": "https://forcheetah.github.io/2025/04/27/Tengine02/",
            "title": "【Tengine】推理流程脑图【2】",
            "date_published": "2025-04-27T13:17:52.829Z",
            "content_html": "<h1 id=\"前言\"><a class=\"anchor\" href=\"#前言\">#</a> 前言</h1>\n<p>本篇通流程脑图和代码介绍 Tengine 推理引擎的推理流程。本篇是第二篇。第一篇<a href=\"https://forcheetah.github.io/2025/04/24/Tengine01/\">地址</a>。<a href=\"https://github.com/OAID/Tengine\">Tengine 工程地址</a>。</p>\n<p>作为初学者，错误在所难免，还望不吝赐教。</p>\n<h1 id=\"介绍\"><a class=\"anchor\" href=\"#介绍\">#</a> 介绍</h1>\n<p><img loading=\"lazy\" data-src=\"1745759345300.jpg\" alt=\"Tengine\"></p>\n<p>Tengine 由 OPEN AI LAB 主导开发，该项目实现了深度学习神经网络模型在嵌入式设备上的快速、高效部署需求。为实现在众多 AIoT 应用中的跨平台部署，该项目使用 C 语言进行核心模块开发，针对嵌入式设备资源有限的特点进行了深度框架裁剪。同时采用了完全分离的前后端设计，有利于 CPU、GPU、NPU 等异构计算单元的快速移植和部署，降低评估、迁移成本。</p>\n<h1 id=\"总流程图\"><a class=\"anchor\" href=\"#总流程图\">#</a> 总流程图</h1>\n<p>总流程图：</p>\n<p><img loading=\"lazy\" data-src=\"1745759400512.jpg\" alt=\"Tengine推理流程图\"></p>\n<p><code>init_tengine()</code>  和  <code>create_graph()</code>  流程位于第一篇<a href=\"https://forcheetah.github.io/2025/04/24/Tengine01/\">地址</a>中。</p>\n<h1 id=\"prerun_graph_multithread\"><a class=\"anchor\" href=\"#prerun_graph_multithread\">#</a> prerun_graph_multithread()</h1>\n<p><img loading=\"lazy\" data-src=\"1745759572184.jpg\" alt=\"prerun_graph_multithread推理流程图\"></p>\n<p>该函数是神经网络模型运行前的与运行流程。从流程图中看，其主要调用了三个函数。</p>\n<h2 id=\"1infer_ir_graph_shape\"><a class=\"anchor\" href=\"#1infer_ir_graph_shape\">#</a> 1.infer_ir_graph_shape()</h2>\n<p>推理引擎要根据输入 tensor 的维度来推理输出 tensor 的维度。例如某个卷积节点的输入维度是【1，32，128，128】，依据 kernel 大小计算出输出维度【1,64,128,128】。所以该函数会按顺序执行所有节点，并调用每个节点的 <code>op-&gt;infer_shape</code>  方法（前述提到过），完成整个模型的 tensor 维度推理。</p>\n<h2 id=\"2optimizer-split_graph\"><a class=\"anchor\" href=\"#2optimizer-split_graph\">#</a> 2.optimizer-&gt;split_graph()</h2>\n<p>切分子图。这是一个为了实现多设备运行而实现的方法，即通过切分子图实现。</p>\n<p>当前已有一个总图，包含模型所有的节点。而设备可能包括 CPU、GPU、NPU、DNNL 等等，而这些设备可能仅支持一部分算子，这就要求将总图切分成设备支持的子图，和设备不支持的子图。设备支持的子图交给设备运行，不支持的交给 CPU 执行。</p>\n<p>经过这个函数之后，子图就变成一各执行单元。</p>\n<h2 id=\"3schedule-prerun\"><a class=\"anchor\" href=\"#3schedule-prerun\">#</a> 3.schedule-&gt;prerun()</h2>\n<p>预运行，其调用的是 <code>interface-&gt;prerun()</code> ，即前述的，和设备相关的接口中的 <code>prerun()</code>  函数。其又调用了三个函数：</p>\n<p><code>create_exec_graph()</code> ：为每个子图创建执行子图。</p>\n<p>通过 <code>find_node_ops()</code>  函数，找到节点的所有执行方式。前述卷积算法，就注册了三种执行方式。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre>ret <span class=\"token operator\">=</span> <span class=\"token function\">register_conv_ref_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_conv_dw_hcl_x86_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_conv_hcl_x86_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>找到所有执行方式之后，调用每种执行方式的 <code>node_ops-&gt;score()</code>  函数，获得一个得分。例如 <code>conv_hcl_x86_op</code>  这种实现方式，其 <code>score()</code>  函数如下。它根据该节点的参数返回一个得分。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">static</span> <span class=\"token keyword\">int</span> <span class=\"token function\">score</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">struct</span> <span class=\"token class-name\">node_ops</span><span class=\"token operator\">*</span> node_ops<span class=\"token punctuation\">,</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">exec_graph</span><span class=\"token operator\">*</span> exec_graph<span class=\"token punctuation\">,</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">node</span><span class=\"token operator\">*</span> exec_node<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">struct</span> <span class=\"token class-name\">node</span><span class=\"token operator\">*</span> ir_node <span class=\"token operator\">=</span> exec_node<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">struct</span> <span class=\"token class-name\">graph</span><span class=\"token operator\">*</span> ir_graph <span class=\"token operator\">=</span> ir_node<span class=\"token operator\">-></span>graph<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">struct</span> <span class=\"token class-name\">tensor</span><span class=\"token operator\">*</span> input_tensor <span class=\"token operator\">=</span> <span class=\"token function\">get_ir_graph_tensor</span><span class=\"token punctuation\">(</span>ir_graph<span class=\"token punctuation\">,</span> ir_node<span class=\"token operator\">-></span>input_tensors<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">struct</span> <span class=\"token class-name\">tensor</span><span class=\"token operator\">*</span> output_tensor <span class=\"token operator\">=</span> <span class=\"token function\">get_ir_graph_tensor</span><span class=\"token punctuation\">(</span>ir_graph<span class=\"token punctuation\">,</span> ir_node<span class=\"token operator\">-></span>output_tensors<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">struct</span> <span class=\"token class-name\">conv_param</span><span class=\"token operator\">*</span> param <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">struct</span> <span class=\"token class-name\">conv_param</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span>exec_node<span class=\"token operator\">-></span>op<span class=\"token punctuation\">.</span>param_mem<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token keyword\">int</span> group <span class=\"token operator\">=</span> param<span class=\"token operator\">-></span>group<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">int</span> kernel_h <span class=\"token operator\">=</span> param<span class=\"token operator\">-></span>kernel_h<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token keyword\">int</span> kernel_w <span class=\"token operator\">=</span> param<span class=\"token operator\">-></span>kernel_w<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token keyword\">int</span> in_c <span class=\"token operator\">=</span> input_tensor<span class=\"token operator\">-></span>dims<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> group<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token keyword\">int</span> out_c <span class=\"token operator\">=</span> output_tensor<span class=\"token operator\">-></span>dims<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">/</span> group<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre></pre></td></tr><tr><td data-num=\"14\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>input_tensor<span class=\"token operator\">-></span>data_type <span class=\"token operator\">!=</span> TENGINE_DT_FP32 <span class=\"token operator\">&amp;&amp;</span> input_tensor<span class=\"token operator\">-></span>data_type <span class=\"token operator\">!=</span> TENGINE_DT_UINT8 <span class=\"token operator\">&amp;&amp;</span> input_tensor<span class=\"token operator\">-></span>data_type <span class=\"token operator\">!=</span> TENGINE_DT_INT8<span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"15\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// 返回 0 得分，意思是无法使用</span></pre></td></tr><tr><td data-num=\"16\"></td><td><pre></pre></td></tr><tr><td data-num=\"17\"></td><td><pre>    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>group <span class=\"token operator\">!=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"18\"></td><td><pre>        <span class=\"token keyword\">return</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>  <span class=\"token comment\">// 返回 0 得分，意思是无法使用</span></pre></td></tr><tr><td data-num=\"19\"></td><td><pre></pre></td></tr><tr><td data-num=\"20\"></td><td><pre>    <span class=\"token keyword\">return</span> OPS_SCORE_PREFER<span class=\"token punctuation\">;</span>   <span class=\"token comment\">// 返回 OPS_SCORE_PREFER 得分，意思是推荐使用</span></pre></td></tr><tr><td data-num=\"21\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>得分分为以下几档：</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name\">OPS_SCORE_STATIC</span> <span class=\"token expression\"><span class=\"token number\">10000</span></span></span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name\">OPS_SCORE_BEST</span>   <span class=\"token expression\"><span class=\"token number\">8000</span></span></span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name\">OPS_SCORE_PREFER</span> <span class=\"token expression\"><span class=\"token number\">6000</span></span></span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name\">OPS_SCORE_CANDO</span>  <span class=\"token expression\"><span class=\"token number\">4000</span></span></span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">define</span> <span class=\"token macro-name\">OPS_SCORE_NOTSUP</span> <span class=\"token expression\"><span class=\"token number\">2000</span></span></span></pre></td></tr></table></figure><p>推理引擎将选择得分最高的作为执行方法，而得分低于 4000 的方法不可使用。</p>\n<p>下一步是调用 <code>node_ops-&gt;init_node()</code>  函数，是初始化节点预留的接口。</p>\n<p>通过 <code>prerun_exec_graph()</code>  函数调用 <code>node_ops-&gt;prerun()</code> ，这个是节点预运行而预留的接口。</p>\n<h1 id=\"run_graph\"><a class=\"anchor\" href=\"#run_graph\">#</a> run_graph()</h1>\n<p><img loading=\"lazy\" data-src=\"1745759741353.jpg\" alt=\"run_graph推理流程图\"></p>\n<p>到这里才开始实际执行图的每个节点。</p>\n<p>和前述一样，还是调用和设备相关的接口 <code>interface-&gt;run()</code> ，先调用每个算子的 <code>node_ops-&gt;reshape()</code>  函数，从工程中来看该函数仍然是在做维度推理的工作，与前述的 <code>infer_shape()</code>  相同。似乎是重复的做法，不过不同之处在于前述的 <code>infer_shape()</code>  只在模型构建完成之后运行一次，而这个 <code>reshape()</code>  函数在算子每次执行之前都要调用。</p>\n<p>可能是为了防止模型的每次运行，输入 tensor 大小都不一样？毕竟神经网络模型通常会不断输入数据，重复运行。（当开发者确定每次输入输入维度一致时，这里的运算就有些浪费时间了。）</p>\n<p>然后调用算子的具体执行： <code>node_ops-&gt;run()</code> 。</p>\n<h1 id=\"postrun_graph\"><a class=\"anchor\" href=\"#postrun_graph\">#</a> postrun_graph()</h1>\n<p><img loading=\"lazy\" data-src=\"1745759761537.jpg\" alt=\"postrun_graoh推理流程图\"></p>\n<p>图的后处理。</p>\n<p>调用每个节点的后运行  <code>node_ops-&gt;postrun()</code></p>\n<p>调用子图的释放函数 <code>release_exec_graph()</code> ，调用每个节点的释放函数 <code>node_ops-&gt;release_node()</code> 。</p>\n<h1 id=\"destroy_graph\"><a class=\"anchor\" href=\"#destroy_graph\">#</a> destroy_graph()</h1>\n<p><img loading=\"lazy\" data-src=\"1745759830848.jpg\" alt=\"destroy_graph推理流程图\"></p>\n<p>调用整个图的释放函数 <code>interface-&gt;release_graph()</code> 。</p>\n<p>一张脑图就帮我们整体把握 Tengine 推理引擎。</p>\n<h1 id=\"后记\"><a class=\"anchor\" href=\"#后记\">#</a> 后记</h1>\n<p>本博客目前以及可预期的将来都不会支持评论功能。各位大侠如若有指教和问题，可以在我的 <a href=\"https://github.com/ForCheetah/ForCheetah.github.io\">github 项目</a> 或随便一个项目下提出 issue，并指明哪一篇博客，我看到一定及时回复！</p>\n",
            "tags": [
                "compiler"
            ]
        },
        {
            "id": "https://forcheetah.github.io/2025/04/24/Tengine01/",
            "url": "https://forcheetah.github.io/2025/04/24/Tengine01/",
            "title": "【Tengine】推理流程脑图【1】",
            "date_published": "2025-04-24T12:13:25.414Z",
            "content_html": "<h1 id=\"前言\"><a class=\"anchor\" href=\"#前言\">#</a> 前言</h1>\n<p>本篇通过流程脑图和代码介绍 Tengine 推理引擎的推理流程。本篇是第一部分。<a href=\"https://github.com/OAID/Tengine\">Tengine 工程地址</a>。</p>\n<p>作为初学者，错误在所难免，还望不吝赐教。</p>\n<h1 id=\"介绍\"><a class=\"anchor\" href=\"#介绍\">#</a> 介绍</h1>\n<p><img loading=\"lazy\" data-src=\"1745496368199.jpg\" alt=\"Tengine\"></p>\n<p>Tengine 由 OPEN AI LAB 主导开发，该项目实现了深度学习神经网络模型在嵌入式设备上的快速、高效部署需求。为实现在众多 AIoT 应用中的跨平台部署，该项目使用 C 语言进行核心模块开发，针对嵌入式设备资源有限的特点进行了深度框架裁剪。同时采用了完全分离的前后端设计，有利于 CPU、GPU、NPU 等异构计算单元的快速移植和部署，降低评估、迁移成本。</p>\n<h1 id=\"推理流程\"><a class=\"anchor\" href=\"#推理流程\">#</a> 推理流程</h1>\n<p>不了解 AI 推理引擎的人，可能难以理解推理引擎做了哪些工作。所以我画了一张流程图，该流程图介绍了 Tengine 推理引擎在推理神经网络的时候做了哪些事情。通过这张图，不仅能全局掌握 Tengine 的推理流程，还能对推理引擎有更深刻的认识。</p>\n<p>直接上图：</p>\n<p><img loading=\"lazy\" data-src=\"1745496426999.jpg\" alt=\"Tengine推理流程图\"></p>\n<p>图中是一大批函数名字和他们之间的链接关系。我们先从左边入手，左边红色连线分别是 <code>init_tengine()</code> 、 <code>Create_graph()</code> 、 <code>prerun_graph_multithread()</code> 、 <code>run_graph()</code> 、 <code>get_graph_output_tensor()</code> 、 <code>postrun_graoh()</code>  和 <code>destroy_graph()</code> 。这些函数名通俗易懂，我们挨个来描述他们的详细功能。</p>\n<h1 id=\"init_tengine\"><a class=\"anchor\" href=\"#init_tengine\">#</a> init_tengine()</h1>\n<p><img loading=\"lazy\" data-src=\"1745496461827.jpg\" alt=\"init_tengine推理流程图\"></p>\n<p>顾名思义，该函数完成推理引擎的初始化。分为三个步骤：注册算子原型、注册序列化工具、注册设备。</p>\n<h2 id=\"1注册算子原型register_all_op_prototype\"><a class=\"anchor\" href=\"#1注册算子原型register_all_op_prototype\">#</a> 1. 注册算子原型：register_all_op_prototype ()</h2>\n<p>该函数将在编译的过程中生成在 build 文件夹里。该函数将调用一百多个算子原型的注册函数。如下：</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> <span class=\"token function\">register_all_op_prototype</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_argmax_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_const_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_convolution_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_crop_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_deconvolution_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>以注册卷积算子为例， <code>register_convolution_op()</code>  函数注册了卷积算子对应的初始化函数 <code>init_op</code>  和释放函数 <code>release_op</code> 。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> <span class=\"token function\">register_convolution_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    ir_method_t m<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    m<span class=\"token punctuation\">.</span>version <span class=\"token operator\">=</span> <span class=\"token number\">1</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    m<span class=\"token punctuation\">.</span>init <span class=\"token operator\">=</span> init_op<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    m<span class=\"token punctuation\">.</span>release <span class=\"token operator\">=</span> release_op<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token keyword\">return</span> <span class=\"token function\">register_op</span><span class=\"token punctuation\">(</span>OP_CONV<span class=\"token punctuation\">,</span> OP_CONV_NAME<span class=\"token punctuation\">,</span> <span class=\"token operator\">&amp;</span>m<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>初始化函数 <code>init_op</code>  为卷积参数 <code>conv_param</code>  开辟空间（保存 kernel shape、pad 等信息），同时注册了维度推理函数 <code>infer_shape</code> （根据输入 tensor 和 kernel 维度推理输出 tensor 维度）。</p>\n<h2 id=\"2注册序列化工具register_all_serializer\"><a class=\"anchor\" href=\"#2注册序列化工具register_all_serializer\">#</a> 2. 注册序列化工具：register_all_serializer ()</h2>\n<p>它调用了两个函数。</p>\n<p>1. <code>register_tm2_serializer()</code> ，就是注册序列化 tmfile 模型文件的工具。该工具静态结构体 <code>tm2_serializer</code>  如下所示，可用来读取内存，加载模型等。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">static</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">tm2_serializer</span> tm2_serializer <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span>base <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token punctuation\">.</span>get_name <span class=\"token operator\">=</span> get_name<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token punctuation\">.</span>load_model <span class=\"token operator\">=</span> load_model<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        <span class=\"token punctuation\">.</span>load_mem <span class=\"token operator\">=</span> load_mem<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token punctuation\">.</span>unload_graph <span class=\"token operator\">=</span> unload_graph<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token punctuation\">.</span>register_op_loader <span class=\"token operator\">=</span> register_op_loader<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token punctuation\">.</span>unregister_op_loader <span class=\"token operator\">=</span> unregister_op_loader<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>        <span class=\"token punctuation\">.</span>init <span class=\"token operator\">=</span> init_tm2_serializer<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>        <span class=\"token punctuation\">.</span>release <span class=\"token operator\">=</span> release_tm2_serializer<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre>    <span class=\"token punctuation\">.</span>loader_list <span class=\"token operator\">=</span> <span class=\"token constant\">NULL</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"13\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>2. <code>register_all_tm2_ops()</code>  函数用于注册所有算子的加载工具。不同的算子参数不同，数据不同，需要注册不同的加载函数。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> <span class=\"token function\">register_all_tm2_ops</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_tm2_concat_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_tm2_conv_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_tm2_crop_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>以卷积算子为例， <code>register_tm2_conv_op()</code>  函数的内容是：调用前述静态结构体 <code>tm2_serializer</code>  的 <code>register_op_loader()</code>  函数，将卷积算子的加载函数 <code>tm2_load_conv</code>  注册进去，用于模型中卷积节点的加载。</p>\n<h2 id=\"3注册设备register_all_devices\"><a class=\"anchor\" href=\"#3注册设备register_all_devices\">#</a> 3. 注册设备：register_all_devices ()</h2>\n<p>作为支持多平台设备的推理引擎，设备管理也必不可少。编译阶段需要指定目标设备，我们以 CPU 为例，该函数将调用 <code>register_cpu_device()</code>  来注册 CPU 设备。</p>\n<p><code>cpu_device</code>  是个静态结构体，其包含了接口 <code>interface</code> 、分配器 <code>allocator</code> 、优化器 <code>optimizer</code> 。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">static</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">cpu_device</span> cpu_dev <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span>base <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>        <span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> CPU_DEVICE_NAME<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>        <span class=\"token punctuation\">.</span>interface <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>cpu_interface<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>        <span class=\"token punctuation\">.</span>allocator <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>cpu_allocator<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>        <span class=\"token punctuation\">.</span>optimizer <span class=\"token operator\">=</span> <span class=\"token operator\">&amp;</span>cpu_optimizer<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>        <span class=\"token punctuation\">.</span>scheduler <span class=\"token operator\">=</span> <span class=\"token constant\">NULL</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>        <span class=\"token punctuation\">.</span>privacy <span class=\"token operator\">=</span> <span class=\"token constant\">NULL</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre>    <span class=\"token punctuation\">.</span>master_cpu <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"11\"></td><td><pre>    <span class=\"token punctuation\">.</span>cpu_model <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"12\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>着重看一下 CPU 设备的接口，接口 <code>cpu_interface</code>  也是一个静态结构体：</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">static</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">interface</span> cpu_interface <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span>init <span class=\"token operator\">=</span> init_cpu<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token punctuation\">.</span>pre_run <span class=\"token operator\">=</span> prerun<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token punctuation\">.</span>run <span class=\"token operator\">=</span> run<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token punctuation\">.</span>post_run <span class=\"token operator\">=</span> postrun<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token punctuation\">.</span>async_run <span class=\"token operator\">=</span> <span class=\"token constant\">NULL</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token punctuation\">.</span>async_wait <span class=\"token operator\">=</span> <span class=\"token constant\">NULL</span><span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token punctuation\">.</span>release_graph <span class=\"token operator\">=</span> cpu_dev_release_exec_graph<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre>    <span class=\"token punctuation\">.</span>release_device <span class=\"token operator\">=</span> release_cpu<span class=\"token punctuation\">,</span></pre></td></tr><tr><td data-num=\"10\"></td><td><pre><span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">;</span></pre></td></tr></table></figure><p>接口包含 CPU 设备初始化 <code>init</code> 、预运行 <code>pre_run</code> 、运行 <code>run</code> 、后运行 <code>post_run</code> 。</p>\n<p>当前会调用 CPU 设备初始化 <code>init</code> ，其余的会在后续调用到。</p>\n<p>CPU 设备初始化函数 <code>init_cpu</code>  会调用 <code>register_all_cpu_ops()</code>  函数，来注册所有 CPU 算子实现。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">int</span> <span class=\"token function\">register_all_cpu_ops</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_concat_ref_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_conv_ref_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_conv_dw_hcl_x86_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_conv_hcl_x86_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    ret <span class=\"token operator\">=</span> <span class=\"token function\">register_crop_ref_op</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre>    <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></pre></td></tr><tr><td data-num=\"9\"></td><td><pre><span class=\"token punctuation\">&#125;</span></pre></td></tr></table></figure><p>从这段代码中看到，卷积算子的推理方式注册了三个。这是因为即使同一个设备的同一个算子，也可能有不同的实现方法，有些推理方法速度更快，但是有限制条件。所以具体使用哪个方法，会在后续流程中介绍。</p>\n<h1 id=\"create_graph\"><a class=\"anchor\" href=\"#create_graph\">#</a> Create_graph()</h1>\n<p><img loading=\"lazy\" data-src=\"1745496726346.jpg\" alt=\"Create_graph推理流程图\"></p>\n<p>该函数完成模型图结构的创建过程。</p>\n<h2 id=\"1创建上下文create_context\"><a class=\"anchor\" href=\"#1创建上下文create_context\">#</a> 1. 创建上下文：create_context ()</h2>\n<p>Context 是图执行的上下文，它会绑定调度器、设备等信息。这里不过多解释。</p>\n<figure class=\"highlight cpp\"><figcaption data-lang=\"C++\"></figcaption><table><tr><td data-num=\"1\"></td><td><pre><span class=\"token keyword\">typedef</span> <span class=\"token keyword\">struct</span> <span class=\"token class-name\">context</span></pre></td></tr><tr><td data-num=\"2\"></td><td><pre><span class=\"token punctuation\">&#123;</span></pre></td></tr><tr><td data-num=\"3\"></td><td><pre>    <span class=\"token keyword\">char</span><span class=\"token operator\">*</span> name<span class=\"token punctuation\">;</span></pre></td></tr><tr><td data-num=\"4\"></td><td><pre>    <span class=\"token keyword\">struct</span> <span class=\"token class-name\">scheduler</span><span class=\"token operator\">*</span> scheduler<span class=\"token punctuation\">;</span> <span class=\"token comment\">//!&lt; binding scheduler of this context</span></pre></td></tr><tr><td data-num=\"5\"></td><td><pre>    <span class=\"token keyword\">struct</span> <span class=\"token class-name\">device</span><span class=\"token operator\">*</span> device<span class=\"token punctuation\">;</span>       <span class=\"token comment\">//!&lt; binding device of this context</span></pre></td></tr><tr><td data-num=\"6\"></td><td><pre>    <span class=\"token keyword\">void</span><span class=\"token operator\">*</span> default_options<span class=\"token punctuation\">;</span>       <span class=\"token comment\">//&lt;! default device options of this context</span></pre></td></tr><tr><td data-num=\"7\"></td><td><pre>    <span class=\"token keyword\">void</span><span class=\"token operator\">*</span> device_options<span class=\"token punctuation\">;</span>        <span class=\"token comment\">//&lt;! device options of this context</span></pre></td></tr><tr><td data-num=\"8\"></td><td><pre><span class=\"token punctuation\">&#125;</span> ir_context_t<span class=\"token punctuation\">;</span></pre></td></tr></table></figure><h2 id=\"2创建图create_ir_graph\"><a class=\"anchor\" href=\"#2创建图create_ir_graph\">#</a> 2. 创建图：create_ir_graph ()</h2>\n<p>该函数主要创建一个新的图，并调用 <code>init_ir_graph()</code>  初始化一些信息，如图的节点数量、tensor 数量、输入输出等，做的事情相当有限。</p>\n<h2 id=\"3加载图结构load_mem\"><a class=\"anchor\" href=\"#3加载图结构load_mem\">#</a> 3. 加载图结构：load_mem ()</h2>\n<p>通过 <code>find_serializer_via_name()</code>  函数找到前述的序列化工具  <code>serializer</code> ，调用其<br>\n运行序列化工具的 <code>load_mem()</code>  函数，解析 tmfile 文件。其中 <code>load_graph</code>  函数会依次调用加载 tensor <code>load_graph_tensors()</code> 、加载节点 <code>load_graph_nodes()</code> 、加载输入输出节点 <code>load_graph_io_nodes()</code> 、加载子图信息 <code>load_graph_sub_info()</code> 。</p>\n<p>后半部分的流程介绍将在下一篇完成。</p>\n<h1 id=\"后记\"><a class=\"anchor\" href=\"#后记\">#</a> 后记</h1>\n<p>本博客目前以及可预期的将来都不会支持评论功能。各位大侠如若有指教和问题，可以在我的 <a href=\"https://github.com/ForCheetah/ForCheetah.github.io\">github 项目</a> 或随便一个项目下提出 issue，并指明哪一篇博客，我看到一定及时回复！</p>\n",
            "tags": [
                "compiler"
            ]
        }
    ]
}