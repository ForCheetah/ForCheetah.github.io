<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta http-equiv="X-UA-COMPATIBLE" content="IE=edge,chrome=1"><meta name="renderer" content="webkit"><link rel="icon" type="image/ico" sizes="32x32" href="/assets/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png"><link rel="alternate" href="/rss.xml" title="Пусть этот камень будет более крепким, чем человек" type="application/rss+xml"><link rel="alternate" href="/atom.xml" title="Пусть этот камень будет более крепким, чем человек" type="application/atom+xml"><link rel="alternate" type="application/json" title="Пусть этот камень будет более крепким, чем человек" href="https://forcheetah.github.io/feed.json"><link rel="preconnect" href="https://lf9-cdn-tos.bytecdntp.com"><link rel="preconnect" href="https://at.alicdn.com"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Mulish:400,400italic,700,700italic%7CFredericka%20the%20Great:400,400italic,700,700italic%7CNoto%20Serif%20JP:400,400italic,700,700italic%7CNoto%20Serif%20SC:400,400italic,700,700italic%7CInconsolata:400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext" media="none" onload="this.media='all'"><link rel="stylesheet" href="/css/app.css?v=0.4.2"><link rel="modulepreload" href="/js/chunk-FJ7AJ5BW.js"><link rel="modulepreload" href="/js/chunk-MQTNP6EI.js"><link rel="modulepreload" href="/js/chunk-QAWHJ5B3.js"><link rel="modulepreload" href="/js/index.esm-SU253EAQ.js"><link rel="modulepreload" href="/js/post-SZ2V6ERD.js"><link rel="modulepreload" href="/js/quicklink-GO25OZIT.js"><link rel="modulepreload" href="/js/siteInit.js"><link rel="preload" href="https://forcheetah.github.io/assets/lunbo13.webp" as="image" fetchpriority="high"><link rel="preload" href="https://forcheetah.github.io/assets/lunbo6.webp" as="image" fetchpriority="high"><link rel="preload" href="https://forcheetah.github.io/assets/lunbo2.webp" as="image" fetchpriority="high"><link rel="preload" href="https://forcheetah.github.io/assets/gamersky.webp" as="image" fetchpriority="high"><link rel="preload" href="https://forcheetah.github.io/assets/lunbo10.webp" as="image" fetchpriority="high"><link rel="preload" href="https://forcheetah.github.io/assets/lunbo4.webp" as="image" fetchpriority="high"><meta name="keywords" content="AI,"><meta name="description" content="有自己的博客很帅，但是我很懒，要命！！！"><link rel="canonical" href="https://forcheetah.github.io/2026/02/01/CUDA03/"><title>【CUDA C++】GPU内存使用【3】</title><meta name="generator" content="Hexo 7.0.0"></head><body itemscope="" itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">【CUDA C++】GPU内存使用【3】</h1><div class="meta"><span class="item" title="Created: 2026-02-01 21:47:17"><span class="icon"><i class="ic i-calendar"></i></span><span class="text">Posted on</span><time itemprop="dateCreated datePublished" datetime="2026-02-01T21:47:17+08:00">2026-02-01</time></span><span class="item" title="Symbols count in article"><span class="icon"><i class="ic i-pen"></i></span><span class="text">Symbols count in article</span><span>7.3k</span><span class="text">words</span></span><span class="item" title="Reading time"><span class="icon"><i class="ic i-clock"></i></span><span class="text">Reading time</span><span>7 mins.</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="Toggle navigation bar"><span class="line"></span><span class="line"></span><span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">暮冬Z羡慕的博客</a></li></ul><ul class="right" id="rightNav"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div class="pjax" id="imgs"><ul><li class="item" style="background-image: url(&quot;https://forcheetah.github.io/assets/lunbo13.webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://forcheetah.github.io/assets/lunbo6.webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://forcheetah.github.io/assets/lunbo2.webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://forcheetah.github.io/assets/gamersky.webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://forcheetah.github.io/assets/lunbo10.webp&quot;);"></li><li class="item" style="background-image: url(&quot;https://forcheetah.github.io/assets/lunbo4.webp&quot;);"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"></path></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"></use><use xlink:href="#gentle-wave" x="48" y="3"></use><use xlink:href="#gentle-wave" x="48" y="5"></use><use xlink:href="#gentle-wave" x="48" y="7"></use></g></svg></div><main><div class="inner"><div class="pjax" id="main"><div class="article wrap"><div class="breadcrumb" itemlistelement="" itemscope="" itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i><span><a href="/">Home</a></span><i class="ic i-angle-right"></i><span class="current" itemprop="itemListElement" itemscope="itemscope" itemtype="https://schema.org/ListItem"><a href="/categories/CUDA/" itemprop="item" rel="index" title="InCUDA"><span itemprop="name">CUDA<meta itemprop="position" content="0"></span></a></span></div><article class="post block" itemscope="itemscope" itemtype="http://schema.org/Article" lang="en"><link itemprop="mainEntityOfPage" href="https://forcheetah.github.io/2026/02/01/CUDA03/"><span hidden="hidden" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><meta itemprop="image" content="/assets/avatar.webp"><meta itemprop="name" content="XianMu"><meta itemprop="description" content="神经网络推理、加速、AI编译。 我必须立刻开始挣扎！, 有自己的博客很帅，但是我很懒，要命！！！"></span><span hidden="hidden" itemprop="publisher" itemscope="itemscope" itemtype="http://schema.org/Organization"><meta itemprop="name" content="Пусть этот камень будет более крепким, чем человек"></span><div class="body md" itemprop="articleBody"><h1 id="前言"><a class="anchor" href="#前言">#</a> 前言</h1>
<p>本篇介绍 GPU 的内存使用，主要是全局内存的合并内存访问，和共享内存的 bank 冲突。资料来源于 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-programming-guide/contents.html">官网 CUDA Programming Guide</a>。本文会比官网教程简洁一些，去掉一些我不太感兴趣的内容（任性）。</p>
<p>参考  <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-programming-guide/contents.html">官网 CUDA Programming Guide</a>。</p>
<p>作为初学者，错误在所难免，还望不吝赐教。</p>
<h1 id="gpu合并内存访问"><a class="anchor" href="#gpu合并内存访问">#</a> GPU 合并内存访问</h1>
<p>GPU 的全局内存 Global Memory (GPU  Dram, 常见的显卡 8GB、12GB)，是通过 32-byte memory transactions 进行访问的。<br>
当一个 CUDA 线程从全局内存中请求一个数据字节时，相关的 thread warp 会将该 thread warp 中所有线程的内存请求合并成满足该请求所需的内存交易数量，具体数量取决于每个线程访问的数据字节的大小以及内存地址在各线程中的分布情况。<br>
例如，如果一个线程请求一个 4 字节的数据字节，那么该 Thread warp（包含 32 个 Thread）向全局内存发出的实际内存交易总量将是 32 字节。如果同一 warp 的其他 31 个线程并不需要这 32 字节中的数据，那么数据的利用率很低。而如果一个线程从全局内存中请求一个 4 字节的数据字节，并且交易大小为 32 字节，如果该 Thread warp 中的其他线程可以从这个 32 字节的请求中使用其他 4 字节的数据字节，它们可以在同一个请求中获取所需的数据（合并内存访问）。<br>
举一个简单的例子，如果在 warp 请求中连续的线程在内存中请求连续的 4 个字节的数据，那么该 warp 将合并他们的请求，共请求 128 个字节的内存，而这 128 个字节的数据将通过四次 32 字节的内存操作来获取。这就实现了内存系统的 100% 利用率。也就是说，warp 利用了 100% 的内存流量。下图展示了这种完全协同的内存访问示例：</p>
<p><img loading="lazy" data-src="1769953213349.webp" alt="线程合并访存"></p>
<p>与之相反的，最糟糕的情况是，连续的线程（同一个 warp 中的线程）在同一内存位置上访问的数据元素之间相隔至少 32 个字节。在这种情况下，Thread warp 将被迫为每个线程执行一次 32 字节的内存操作，那么内存传输的总字节数将为 32 字节 * 32 Thread = 1024 字节。然而，实际使用的内存量仅为 128 字节（每个 warp 中的每个线程使用 4 字节），因此内存利用率仅为 128 / 1024 = 12.5%。这是对内存系统的极大浪费。下图展示了这种未合并的内存访问示例：</p>
<p><img loading="lazy" data-src="1769953274901.webp" alt="未能实现线程合并访存"></p>
<p>实现合并内存访问最直接的方法是让连续的线程依次访问内存中的连续元素。<br>
例如，对于使用 1D thread block 启动的 kernal，以下的 VecAdd 内核将实现合并内存访问。</p>
<figure class="highlight cpp"><figcaption data-lang="C++"></figcaption><table><tbody><tr><td data-num="1"></td><td><pre>__global__ <span class="token keyword">void</span> <span class="token function">vecAdd</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> A<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> B<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> C<span class="token punctuation">,</span> <span class="token keyword">int</span> vectorLength<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token punctuation">{</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token keyword">int</span> workIndex <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x<span class="token operator">*</span>blockDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">if</span><span class="token punctuation">(</span>workIndex <span class="token operator">&lt;</span> vectorLength<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">{</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        C<span class="token punctuation">[</span>workIndex<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>workIndex<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>workIndex<span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr></tbody></table></figure><p>值得注意的是，并不存在这样的规定，即连续的线程必须访问内存中的连续元素才能实现协同式内存访问，这只是实现协同式访问的常见方式而已。只要线程组中的所有线程以某种线性或置换的方式访问来自相同 32 字节内存段的元素，就会发生协同式内存访问。换句话说，实现协同式内存访问的最佳方式是将使用的字节数与传输的字节数的比例最大化。<br>
确保全局内存访问的正确合并是编写高效 CUDA 内核时最重要的性能考量之一。应用程序必须尽可能高效地利用内存系统。</p>
<p>矩阵转置例子 合并内存访问</p>
<p>将一个  <code>N*N</code>  的 float 型外部矩阵，从 A 转置为 C，这个例子使用 2D grid，并假设使用 32<em>32 线程的 2D 线程块，因此  <code>blockDim.x = 32</code> ， <code>blockDim.y = 32</code> ，每个线程块要操作 32</em>32 的矩阵切块。每个线程都只对矩阵中的一个特定元素进行处理，因此无需对线程进行显式的同步操作。图 12 展示了这一矩阵转置操作。内核源代码与该图相对应。</p>
<p><img loading="lazy" data-src="1769953336088.webp" alt="矩阵置换示意图"></p>
<p>每个矩阵顶部和左侧的标签分别是二维线程块的索引，也可以视为分块索引，其中每个小方块代表矩阵中将由二维线程块处理的一个分块。在这个例子中，分块大小为 32 x 32 个元素，因此每个小方块代表矩阵的一个 32 x 32 的分块。绿色阴影方块显示了一个示例分块在转置操作前后的位置。<br>
注分块矩阵转置，块的位置转置（即行列互换）每个块自身也转置。：<br>
<img loading="lazy" data-src="1769953350197.webp" alt="分块矩阵转置"></p>
<p>此外，提前介绍一下 CUDA C++ 代码中关于线程用到的参数变量：<br>
<img loading="lazy" data-src="1769953364342.webp" alt="参数示意图"></p>
<figure class="highlight cpp"><figcaption data-lang="C++"></figcaption><table><tbody><tr><td data-num="1"></td><td><pre><span class="token comment">/* macro to index a 1D memory array with 2D indices in row-major order */</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">/* ld is the leading dimension, i.e. the number of columns in the matrix     */</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name function">INDX</span><span class="token expression"><span class="token punctuation">(</span> row<span class="token punctuation">,</span> col<span class="token punctuation">,</span> ld <span class="token punctuation">)</span> <span class="token punctuation">(</span> <span class="token punctuation">(</span> <span class="token punctuation">(</span>row<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>ld<span class="token punctuation">)</span> <span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>col<span class="token punctuation">)</span> <span class="token punctuation">)</span></span></span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">/* CUDA kernel for naive matrix transpose */</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>__global__ <span class="token keyword">void</span> <span class="token function">naive_cuda_transpose</span><span class="token punctuation">(</span><span class="token keyword">int</span> m<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>a<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>c <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token punctuation">{</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token keyword">int</span> myCol <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">int</span> myRow <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">if</span><span class="token punctuation">(</span> myRow <span class="token operator">&lt;</span> m <span class="token operator">&amp;&amp;</span> myCol <span class="token operator">&lt;</span> m <span class="token punctuation">)</span><span class="token punctuation">{</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        c<span class="token punctuation">[</span><span class="token function">INDX</span><span class="token punctuation">(</span> myCol<span class="token punctuation">,</span> myRow<span class="token punctuation">,</span> m <span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token function">INDX</span><span class="token punctuation">(</span> myRow<span class="token punctuation">,</span> myCol<span class="token punctuation">,</span> m <span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token punctuation">}</span> <span class="token comment">/* end if */</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">return</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="17"></td><td><pre><span class="token punctuation">}</span> <span class="token comment">/* end naive_cuda_transpose */</span></pre></td></tr></tbody></table></figure><p>以上代码：</p>
<ul>
<li>每个 CUDA 线程通过自己的 (blockIdx, threadIdx) 计算出它在逻辑二维网格中的位置 (myRow, myCol)。</li>
<li>这个位置直接对应输入矩阵 a 中的一个元素：a [myRow][myCol]。<br>
有对应的位置，线程 (myRow, myCol) 负责读取 a [myRow][myCol]，并将其写入 c [myCol][myRow]<br>
 假设位于 global memory 中的待转置矩阵是按照行主序连续存放的（一般都是这样），那么由以上代码可知，取数据阶段，同一 warp 中的 32 个线程所需的数据是连续的，因此可以合并访存，效率很高，如下图所示：</li>
</ul>
<p><img loading="lazy" data-src="1769953414177.webp" alt="合并访存示意图"></p>
<p>而这 32 个线程在存储结果的时候，相互之间数据间隔超过 32 个字节，无法合并访存，效率很低。</p>
<h1 id="共享内存访问"><a class="anchor" href="#共享内存访问">#</a> 共享内存访问</h1>
<p>共享内存有 32 个存储单元，其组织方式是：连续的 32 位数据会映射到连续的存储单元上。每个存储单元的带宽为每时钟周期 32 位。<br>
当同一线程 warp 中的多个线程试图访问同一缓存区中的不同元素时，就会发生缓存冲突。在这种情况下，对该缓存区中的数据的访问将被串行化处理，直到所有请求该数据的线程都获取到该数据为止。这种访问的串行化会导致性能下降。<br>
这种情况的两个例外情况发生在同一 warp 中的多个线程同时访问（无论是读取还是写入）同一个共享内存位置时。对于读取操作，数据会被广播给请求的线程。对于写入操作，每个共享内存地址仅由其中的一个线程进行写入（哪个线程执行写入操作是不确定的）。<br>
下图展示了一些分段访问的示例。内存 bank 内的红色方框表示共享内存中的一个特定位置。图中，左边和右边示例都没有访问冲突，但是中间示例有两路访问冲突。</p>
<p><img loading="lazy" data-src="1769953435830.webp" alt="bank访问示意图"></p>
<p>另一个示例，如下图所示：<br>
左图：通过随机排列实现无冲突访问。<br>
中图：由于线程 3、4、6、7 和 9 都访问了同一存储单元中的第 5 个存储器组，所以实现了无冲突访问。<br>
右图：无冲突广播访问（同 warp 内的线程访问同一存储单元）。<br>
<img loading="lazy" data-src="1769953452832.webp" alt="bank访问示意图"></p>
<h1 id="矩阵转置例子-使用共享内存"><a class="anchor" href="#矩阵转置例子-使用共享内存">#</a> 矩阵转置例子 使用共享内存</h1>
<p>在上一个 “使用全局内存的矩阵转置示例” 中，展并未针对全局内存的高效使用进行优化，因为 c 矩阵的写入操作没有得到恰当的合并。在本示例中，共享内存将被视为用户管理的缓存，用于在全局内存中进行加载和存储操作，从而实现矩阵转置例子的读和写操作的全局内存合并访问。</p>
<figure class="highlight cpp"><figcaption data-lang="C++"></figcaption><table><tbody><tr><td data-num="1"></td><td><pre><span class="token comment">/* definitions of thread block size in X and Y directions */</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">THREADS_PER_BLOCK_X</span> <span class="token expression"><span class="token number">32</span></span></span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">THREADS_PER_BLOCK_Y</span> <span class="token expression"><span class="token number">32</span></span></span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">/* macro to index a 1D memory array with 2D indices in column-major order */</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment">/* ld is the leading dimension, i.e. the number of rows in the matrix     */</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name function">INDX</span><span class="token expression"><span class="token punctuation">(</span> row<span class="token punctuation">,</span> col<span class="token punctuation">,</span> ld <span class="token punctuation">)</span> <span class="token punctuation">(</span> <span class="token punctuation">(</span> <span class="token punctuation">(</span>col<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>ld<span class="token punctuation">)</span> <span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>row<span class="token punctuation">)</span> <span class="token punctuation">)</span></span></span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment">/* CUDA kernel for shared memory matrix transpose */</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>__global__ <span class="token keyword">void</span> <span class="token function">smem_cuda_transpose</span><span class="token punctuation">(</span><span class="token keyword">int</span> m<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>                                    <span class="token keyword">float</span> <span class="token operator">*</span>a<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                                    <span class="token keyword">float</span> <span class="token operator">*</span>c <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre><span class="token punctuation">{</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token comment">/* declare a statically allocated shared memory array */</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre>    __shared__ <span class="token keyword">float</span> smemArray<span class="token punctuation">[</span>THREADS_PER_BLOCK_X<span class="token punctuation">]</span><span class="token punctuation">[</span>THREADS_PER_BLOCK_Y<span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token comment">/* determine my row and column indices for the error checking code */</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token keyword">const</span> <span class="token keyword">int</span> myRow <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">const</span> <span class="token keyword">int</span> myCol <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment">/* determine my row tile and column tile index */</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token keyword">const</span> <span class="token keyword">int</span> tileX <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token keyword">const</span> <span class="token keyword">int</span> tileY <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token keyword">if</span><span class="token punctuation">(</span> myRow <span class="token operator">&lt;</span> m <span class="token operator">&amp;&amp;</span> myCol <span class="token operator">&lt;</span> m <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token punctuation">{</span></pre></td></tr><tr><td data-num="34"></td><td><pre>        <span class="token comment">/* read from global memory into shared memory array */</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        smemArray<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token function">INDX</span><span class="token punctuation">(</span> tileX <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">,</span> tileY <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">,</span> m <span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token punctuation">}</span> <span class="token comment">/* end if */</span></pre></td></tr><tr><td data-num="37"></td><td><pre></pre></td></tr><tr><td data-num="38"></td><td><pre>    <span class="token comment">/* synchronize the threads in the thread block */</span></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token keyword">if</span><span class="token punctuation">(</span> myRow <span class="token operator">&lt;</span> m <span class="token operator">&amp;&amp;</span> myCol <span class="token operator">&lt;</span> m <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>    <span class="token punctuation">{</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        <span class="token comment">/* write the result from shared memory to global memory */</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        c<span class="token punctuation">[</span><span class="token function">INDX</span><span class="token punctuation">(</span> tileY <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">,</span> tileX <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">,</span> m <span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> smemArray<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="45"></td><td><pre>    <span class="token punctuation">}</span> <span class="token comment">/* end if */</span></pre></td></tr><tr><td data-num="46"></td><td><pre>    <span class="token keyword">return</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="47"></td><td><pre></pre></td></tr><tr><td data-num="48"></td><td><pre><span class="token punctuation">}</span> <span class="token comment">/* end smem_cuda_transpose */</span></pre></td></tr></tbody></table></figure><p>上述代码，第一步  <code>smemArray[threadIdx.x][threadIdx.y] = a[INDX( tileX + threadIdx.x, tileY + threadIdx.y, m )];</code>  将 global memory 中的数据保存至共享内存中，这个过程已经完成了 Tile 块内的数据转置。读取全局内存的过程中， <code>threadIdx.x</code>  经 <code>INDX( row, col, ld ) ( ( (col) * (ld) ) + (row) )</code>  映射后，地址连续变化，所以在读取内存中，已经合并内存访问。<br>
第二步  <code>c[INDX( tileY + threadIdx.x, tileX + threadIdx.y, m )] = smemArray[threadIdx.y][threadIdx.x];</code> ，将共享内存中的数据搬到 global memory 中的指定位置。同样的，在存储过程中， <code>threadIdx.x</code>  连续变化，C [] 地址也连续变化，也实现了合并访存。</p>
<p>这段代码展示了共享内存的两种常见用途。<br>
共享内存用于将数据从全局内存中转移出来，以确保对全局内存的读取和写入操作都能得到正确地合并处理。<br>
共享内存用于使同一线程块中的各个线程能够相互共享数据。</p>
<p>但上述代码存在共享内存的 bank 冲突。<br>
GPU 的 share memory 有 32 个 bank，每个 bank 的 cache line 长度为 4 字节（32bit），并采用低位交叉的地址映射方式。当我们申请 <code>__shared__ float smemArray[32][32]</code>  的共享内存空间时，第一行 32 个 32float 将分散到 32 个 bank 中。<br>
下图中，同样的颜色属于同一 bank，数字代表 warp。比如草绿色这一列全部是 bank0，数字 0 是 warp0.</p>
<p><img loading="lazy" data-src="1769953518248.webp" alt="bank示意图"></p>
<p>回到刚才的矩阵砖石例子中，我们可以通过检查共享内存的使用情况来判断是否存在 bank 冲突。共享内存的首次使用情况是将全局内存中的数据存储到共享内存中：</p>
<figure class="highlight cpp"><figcaption data-lang="C++"></figcaption><table><tbody><tr><td data-num="1"></td><td><pre>smemArray<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span> <span class="token operator">=</span> a<span class="token punctuation">[</span><span class="token function">INDX</span><span class="token punctuation">(</span> tileX <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">,</span> tileY <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">,</span> m <span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr></tbody></table></figure><p>因为 C++ 数组是按行优先顺序存储的，所以同一 warp 中的连续线程（由连续的 threadIdx.x 值表示），由于 threadIdx.x 是共享内存数组的第一个索引，因此会以 32 个元素的步长访问 smemArray。这会导致 32 路 bank 冲突，如上图 的左图所示。<br>
共享内存的第二种使用方式是将来自共享内存的数据写回全局内存：</p>
<figure class="highlight cpp"><figcaption data-lang="C++"></figcaption><table><tbody><tr><td data-num="1"></td><td><pre>c<span class="token punctuation">[</span><span class="token function">INDX</span><span class="token punctuation">(</span> tileY <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">,</span> tileX <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">,</span> m <span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> smemArray<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr></tbody></table></figure><p>在这种情况下，由于 threadIdx.x 是 smemArray 数组中的第二个索引，同一线程组中的连续线程将以 1 个元素的步长访问 smemArray。这避免了存取冲突，如上图右侧。<br>
如何避免 bank 冲突呢？常见方法是通过在数组的列维度上增加 1 来填充共享内存，具体操作如下：</p>
<figure class="highlight cpp"><figcaption data-lang="C++"></figcaption><table><tbody><tr><td data-num="1"></td><td><pre>__shared__ <span class="token keyword">float</span> smemArray<span class="token punctuation">[</span>THREADS_PER_BLOCK_X<span class="token punctuation">]</span><span class="token punctuation">[</span>THREADS_PER_BLOCK_Y<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr></tbody></table></figure><p><img loading="lazy" data-src="1769953621010.webp" alt="bank避免冲突示意图"></p>
<p>这种方式，可使得共享内存存储和读取的时候，都不会有 bank 冲突。</p>
<h1 id="后记"><a class="anchor" href="#后记">#</a> 后记</h1>
<p>本博客目前以及可预期的将来都不会支持评论功能。各位大侠如若有指教和问题，可以在我的 <a target="_blank" rel="noopener" href="https://github.com/ForCheetah/ForCheetah.github.io">github 项目</a> 或随便一个项目下提出 issue，并指明哪一篇博客，看到一定及时回复！</p>
<div class="tags"><a href="/tags/AI/" rel="tag"><i class="ic i-tag"></i>AI</a><a href="/tags/CUDA/" rel="tag"><i class="ic i-tag"></i>CUDA</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i></span><span class="text">Edited on</span><time title="Modified: 2026-02-01 21:47:35" itemprop="dateModified" datetime="2026-02-01T21:47:35+08:00">2026-02-01</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i>Donate</button><p>Give me a cup of [coffee]~(￣▽￣)~*</p><div id="qr"><div><img loading="lazy" data-src="/assets/wechatpay.webp" alt="XianMu WeChat Pay"><p>WeChat Pay</p></div><div><img loading="lazy" data-src="/assets/alipay.webp" alt="XianMu Alipay"><p>Alipay</p></div></div></div><div id="copyright"><ul><li class="author"><strong>Post author: </strong>XianMu<i class="ic i-at"><em>@</em></i>Пусть этот камень будет более крепким, чем человек</li><li class="link"><strong>Post link: </strong><a href="https://forcheetah.github.io/2026/02/01/CUDA03/" title="【CUDA C++】GPU内存使用【3】">https://forcheetah.github.io/2026/02/01/CUDA03/</a></li><li class="license"><strong>Copyright Notice: </strong>All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</a> unless stating additionally.</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/2026/01/25/Cache01/" rel="prev" itemprop="url" data-background-image="https://forcheetah.github.io/assets/gamersky.webp" title="【AI编译】Cache缓存地址映射"><span class="type">Previous Post</span><span class="category"><i class="ic i-flag"></i>compile</span><h3>【AI编译】Cache缓存地址映射</h3></a></div><div class="item right"></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="Contents"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text"> 前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#gpu%E5%90%88%E5%B9%B6%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE"><span class="toc-number">2.</span> <span class="toc-text"> GPU 合并内存访问</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE"><span class="toc-number">3.</span> <span class="toc-text"> 共享内存访问</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE%E4%BE%8B%E5%AD%90-%E4%BD%BF%E7%94%A8%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="toc-number">4.</span> <span class="toc-text"> 矩阵转置例子 使用共享内存</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%90%8E%E8%AE%B0"><span class="toc-number">5.</span> <span class="toc-text"> 后记</span></a></li></ol></div><div class="related panel pjax" data-title="Related"><ul><li><a href="/2026/01/16/CUDA01/" rel="bookmark" title="【CUDA C++】GPU基本介绍【1】">【CUDA C++】GPU基本介绍【1】</a></li><li><a href="/2026/01/16/CUDA02/" rel="bookmark" title="【CUDA C++】GPU存储【2】">【CUDA C++】GPU存储【2】</a></li><li class="active"><a href="/2026/02/01/CUDA03/" rel="bookmark" title="【CUDA C++】GPU内存使用【3】">【CUDA C++】GPU内存使用【3】</a></li></ul></div><div class="overview panel" data-title="Overview"><div class="author" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><img class="image" loading="lazy" decoding="async" itemprop="image" alt="XianMu" src="/assets/avatar.webp"><p class="name" itemprop="name">XianMu</p><div class="description" itemprop="description">有自己的博客很帅，但是我很懒，要命！！！</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">57</span><span class="name">posts</span></a></div><div class="item categories"><a href="/categories/"><span class="count">21</span><span class="name">categories</span></a></div><div class="item tags"><a href="/tags/"><span class="count">23</span><span class="name">tags</span></a></div></nav><div class="social"><a target="_blank" rel="noopener" href="https://github.com/ForCheetah" class="item github" title="https://github.com/ForCheetah"><i class="ic i-github"></i></a><a href="/huasen.w@foxmail.com" class="item email" title="huasen.w@foxmail.com"><i class="ic i-envelope"></i></a></div><div class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>Home</a></li></div></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/2026/01/25/Cache01/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>Random Posts</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/%E7%BC%96%E8%AF%91%E5%99%A8/" title="In编译器">编译器</a></div><span><a href="/2025/03/13/compile01/">【编译器】使用llvm编译自定义语言【1】构建AST</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/tvm/" title="Intvm">tvm</a></div><span><a href="/2024/10/31/tvm05/">【TVM】通过代码学习编译流程【5】FuseOps</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%A1%80%E9%81%97%E6%9C%AF%E7%9A%84%E7%A7%98%E5%AF%86/" title="In血遗术的秘密">血遗术的秘密</a></div><span><a href="/2026/01/03/NOVEL00/">【00】0序章-不受欢迎的来客</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%BD%AC%E8%BD%BD/" title="In转载">转载</a></div><span><a href="/2025/10/06/Article02/">【转载】北大中文男足战报2</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/" title="In问题解决">问题解决</a></div><span><a href="/2025/08/23/problem4/">SystemC 用寄存器同步建模方法</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/halide/" title="Inhalide">halide</a></div><span><a href="/2025/11/15/halide2/">【Halide】调度优化【2】</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/halide/" title="Inhalide">halide</a></div><span><a href="/2025/11/06/halide/">【Halide】调度优化【1】</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/tvm/" title="Intvm">tvm</a></div><span><a href="/2024/06/10/deployTVM/">【TVM】C++部署运行TVM</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/tvm/" title="Intvm">tvm</a></div><span><a href="/2024/10/13/tvm02/">【TVM】通过代码学习编译流程【2】模型转换</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/%E8%BD%AC%E8%BD%BD/" title="In转载">转载</a></div><span><a href="/2025/12/14/Article03/">【转载】我来了——持续低熵</a></span></li></ul></div><div class="rpost pjax"><h2>Recent Comments</h2></div></div><div class="status"><div class="copyright">© 2010 -<span itemprop="copyrightYear">2026</span><span class="with-love"><i class="ic i-sakura rotate"></i></span><span class="author" itemprop="copyrightHolder">XianMu @ 暮冬Z羡慕的博客</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i></span><span title="Symbols count total">358k words</span><span class="post-meta-divider"> | </span><span class="post-meta-item-icon"><i class="ic i-coffee"></i></span><span title="Reading time total">5:25</span></div><div class="powered-by">Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> &amp; Theme.<a target="_blank" rel="noopener" href="https://github.com/theme-shoka-x/hexo-theme-shokaX/">ShokaX</a></div></div></div></footer></div><script data-config="" type="text/javascript">var LOCAL = {
    ispost: true,
        path: `2026/02/01/CUDA03/`,
        favicon: {
        show: `(●´3｀●) Here we go again.`,
        hide: `(´Д｀) It's a disaster!`
    },
    search: {
        placeholder: "Search for Posts",
        empty: "We didn't find any results for the search: ${query}",
        stats: "${hits} results found in ${time} ms"
    },
    copy_tex: false,
    katex: false,
    mermaid: false,
    audio: {},
    fancybox: true,
    nocopy: false,
    outime: true,
    template: `<div class="note warning"><p><span class="label warning">Article Timeliness Alert</span><br>This is an article published {{publish}} days ago and last updated {{updated}} days ago. Some information may have changed, so please be careful to screen it.</p></div>`,
    quiz: {
        choice: `Multiple Choice`,
        multiple: `Multiple Answer`,
        true_false: `True/False`,
        essay: `Questions`,
        gap_fill: `Gap Filling`,
        mistake: `Wrong Answer`
    },
    ignores: [
        (uri) => uri.includes('#'),
        (uri) => new RegExp(LOCAL.path + '$').test(uri),
            []
    ]
};
</script><script src="https://lf9-cdn-tos.bytecdntp.com/cdn/expire-6-M/pace/1.2.4/pace.min.js" async=""></script><script src="/js/siteInit.js?v=0.4.2" type="module" fetchpriority="high" defer=""></script></body></html>